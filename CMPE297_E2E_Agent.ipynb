{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1b64-0gwzOcT"
      },
      "outputs": [],
      "source": [
        "!pip install -q google-adk google-cloud-firestore google-cloud-storage google-auth \\\n",
        "               google-genai gradio python-dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import google.genai as genai\n",
        "\n",
        "os.environ[\"GEMINI_API_KEY\"] = GEMINI_API_KEY\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Quick sanity check\n",
        "resp = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-001\",\n",
        "    contents=\"Say hello in one short sentence.\"\n",
        ")\n",
        "print(resp.text)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "132P-YW0zTiW",
        "outputId": "686ff970-3e15-4558-d200-cbcc5d2ac5e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello there!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "import json\n",
        "import datetime\n",
        "\n",
        "DB_PATH = \"expenses.db\"\n",
        "conn = sqlite3.connect(DB_PATH, check_same_thread=False)\n",
        "cur = conn.cursor()\n",
        "\n",
        "cur.execute(\"\"\"\n",
        "CREATE TABLE IF NOT EXISTS expenses (\n",
        "    id        INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "    user_id   TEXT,\n",
        "    date      TEXT,\n",
        "    merchant  TEXT,\n",
        "    category  TEXT,\n",
        "    total     REAL,\n",
        "    currency  TEXT,\n",
        "    notes     TEXT,\n",
        "    raw_json  TEXT,\n",
        "    created_at TEXT\n",
        ")\n",
        "\"\"\")\n",
        "conn.commit()\n",
        "\n",
        "DEMO_USER_ID = \"demo-user-001\"\n",
        "\n",
        "def insert_expense(user_id: str, expense: dict) -> int:\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        INSERT INTO expenses (user_id, date, merchant, category, total, currency, notes, raw_json, created_at)\n",
        "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
        "        \"\"\",\n",
        "        (\n",
        "            user_id,\n",
        "            expense.get(\"date\", \"\"),\n",
        "            expense.get(\"merchant\", \"\"),\n",
        "            expense.get(\"category\", \"\"),\n",
        "            float(expense.get(\"total\", 0) or 0),\n",
        "            expense.get(\"currency\", \"\"),\n",
        "            expense.get(\"notes\", \"\"),\n",
        "            json.dumps(expense, ensure_ascii=False),\n",
        "            datetime.datetime.utcnow().isoformat(),\n",
        "        ),\n",
        "    )\n",
        "    conn.commit()\n",
        "    return cur.lastrowid\n",
        "\n",
        "def get_recent_expenses(user_id: str, limit: int = 50) -> list[dict]:\n",
        "    cur.execute(\n",
        "        \"\"\"\n",
        "        SELECT id, date, merchant, category, total, currency, notes, raw_json\n",
        "        FROM expenses\n",
        "        WHERE user_id = ?\n",
        "        ORDER BY created_at DESC\n",
        "        LIMIT ?\n",
        "        \"\"\",\n",
        "        (user_id, limit),\n",
        "    )\n",
        "    rows = cur.fetchall()\n",
        "    results = []\n",
        "    for r in rows:\n",
        "        rid, date, merchant, category, total, currency, notes, raw_json = r\n",
        "        try:\n",
        "            raw = json.loads(raw_json)\n",
        "        except Exception:\n",
        "            raw = {}\n",
        "        results.append({\n",
        "            \"id\": rid,\n",
        "            \"date\": date,\n",
        "            \"merchant\": merchant,\n",
        "            \"category\": category,\n",
        "            \"total\": total,\n",
        "            \"currency\": currency,\n",
        "            \"notes\": notes,\n",
        "            \"raw\": raw,\n",
        "        })\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "3fbtkoHP-t2C"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "from google.genai import types\n",
        "import os, json\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Text sanity check\n",
        "resp = client.models.generate_content(\n",
        "    model=\"gemini-2.0-flash-001\",  # or gemini-2.5-flash if allowed\n",
        "    contents=\"Say hello in one short sentence.\",\n",
        ")\n",
        "print(\"TEXT OK:\", resp.text[:80], \"...\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oS4aSOuBB6Ev",
        "outputId": "ca47a893-bb9d-4726-efbf-0256efc5760c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEXT OK: Hello there!\n",
            " ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "\n",
        "import re\n",
        "from io import BytesIO\n",
        "from PIL import Image\n",
        "from google.genai import types\n",
        "\n",
        "def extract_expense_from_receipt(image: Image.Image) -> dict:\n",
        "    \"\"\"\n",
        "    Calls Gemini with the receipt image and asks for structured JSON.\n",
        "    Uses robust JSON extraction so we don't always fall back.\n",
        "    \"\"\"\n",
        "    # Convert PIL image to PNG bytes\n",
        "    buf = BytesIO()\n",
        "    image.save(buf, format=\"PNG\")\n",
        "    img_bytes = buf.getvalue()\n",
        "\n",
        "    prompt = \"\"\"\n",
        "You are an assistant that reads receipt images and extracts structured expense data.\n",
        "\n",
        "You MUST respond with ONLY one JSON object and nothing else:\n",
        "no markdown, no code fences, no explanations.\n",
        "\n",
        "The JSON object should have exactly these keys:\n",
        "- \"date\": ISO date string (yyyy-mm-dd)\n",
        "- \"merchant\": store / merchant name\n",
        "- \"category\": one of [\"groceries\", \"restaurant\", \"coffee\", \"transport\", \"shopping\", \"other\"]\n",
        "- \"total\": number (no currency symbol)\n",
        "- \"currency\": 3-letter code (e.g. \"USD\", \"EUR\", \"INR\")\n",
        "- \"notes\": short free-text summary\n",
        "\"\"\"\n",
        "\n",
        "    parts = [\n",
        "        types.Part.from_text(text=prompt),\n",
        "        types.Part.from_bytes(data=img_bytes, mime_type=\"image/png\"),\n",
        "    ]\n",
        "\n",
        "    response = client.models.generate_content(\n",
        "        model=\"gemini-2.5-flash\",   # vision-capable model\n",
        "        contents=parts,\n",
        "    )\n",
        "\n",
        "    raw_text = (response.text or \"\").strip()\n",
        "    # print(\"RAW MODEL TEXT:\\n\", raw_text[:500])  # uncomment for debugging\n",
        "\n",
        "    # Try to extract a JSON object from the text, even if the model added extra text\n",
        "    json_str = None\n",
        "    m = re.search(r\"\\{.*\\}\", raw_text, flags=re.DOTALL)\n",
        "    if m:\n",
        "        json_str = m.group(0)\n",
        "\n",
        "    if json_str:\n",
        "        try:\n",
        "            data = json.loads(json_str)\n",
        "            # Ensure required keys exist with sensible defaults\n",
        "            data.setdefault(\"date\", \"\")\n",
        "            data.setdefault(\"merchant\", \"\")\n",
        "            data.setdefault(\"category\", \"other\")\n",
        "            data.setdefault(\"total\", 0)\n",
        "            data.setdefault(\"currency\", \"\")\n",
        "            data.setdefault(\"notes\", \"\")\n",
        "            return data\n",
        "        except Exception:\n",
        "            pass  # fall back below\n",
        "\n",
        "    # Fallback: keep the app running and at least store what the model said\n",
        "    return {\n",
        "        \"date\": \"\",\n",
        "        \"merchant\": \"\",\n",
        "        \"category\": \"other\",\n",
        "        \"total\": 0,\n",
        "        \"currency\": \"\",\n",
        "        \"notes\": raw_text[:500],\n",
        "    }\n"
      ],
      "metadata": {
        "id": "2jOIk9oe-1a1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy image just to make sure the call doesn't crash\n",
        "test_img = Image.new(\"RGB\", (200, 100), color=\"white\")\n",
        "\n",
        "print(\"Calling extract_expense_from_receipt on dummy image...\")\n",
        "test_result = extract_expense_from_receipt(test_img)\n",
        "print(\"Got result:\", test_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHp4HvrrDH2i",
        "outputId": "331b52a7-3e9d-46c2-b0b8-bf01c888df41"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calling extract_expense_from_receipt on dummy image...\n",
            "Got result: {'date': '', 'merchant': '', 'category': 'other', 'total': 0.0, 'currency': 'XXX', 'notes': 'Blank receipt image, no expense data found.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def answer_question_over_expenses(user_id: str, question: str, max_rows: int = 50) -> str:\n",
        "    \"\"\"\n",
        "    Retrieves recent expenses from SQLite and lets Gemini answer the question\n",
        "    based ONLY on that data. This is our simple RAG layer.\n",
        "    \"\"\"\n",
        "    expenses = get_recent_expenses(user_id, limit=max_rows)\n",
        "\n",
        "    if not expenses:\n",
        "        base_prompt = (\n",
        "            \"The user has no stored expenses yet. \"\n",
        "            \"Kindly explain that they need to upload some receipts first.\"\n",
        "        )\n",
        "        resp = client.models.generate_content(\n",
        "            model=\"gemini-2.0-flash-001\",\n",
        "            contents=base_prompt,\n",
        "        )\n",
        "        return resp.text\n",
        "\n",
        "    context = json.dumps(expenses, ensure_ascii=False, indent=2)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "You are a personal expense assistant.\n",
        "\n",
        "Here is the user's expense history as JSON:\n",
        "{context}\n",
        "\n",
        "Answer the following question using ONLY this data:\n",
        "\\\"\\\"\\\"{question}\\\"\\\"\\\".\n",
        "\n",
        "- Show totals in the same currency as the data.\n",
        "- If you are unsure because the data doesn't cover it, say so explicitly.\n",
        "- You may show a brief breakdown by merchant/category if helpful.\n",
        "\"\"\"\n",
        "\n",
        "    resp = client.models.generate_content(\n",
        "        model=\"gemini-2.0-flash-001\",\n",
        "        contents=prompt,\n",
        "    )\n",
        "    return resp.text\n"
      ],
      "metadata": {
        "id": "5lNrzEcN-3nq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def chat_fn(message, history, image):\n",
        "    if history is None:\n",
        "        history = []\n",
        "\n",
        "    # ----- Receipt upload flow -----\n",
        "    if image is not None:\n",
        "        user_msg = message or \"Store this receipt\"\n",
        "\n",
        "        try:\n",
        "            expense = extract_expense_from_receipt(image)\n",
        "            expense_id = insert_expense(DEMO_USER_ID, expense)\n",
        "            reply = (\n",
        "                f\"I parsed and stored this receipt as expense #{expense_id}:\\n\"\n",
        "                f\"- Date: {expense.get('date','')}\\n\"\n",
        "                f\"- Merchant: {expense.get('merchant','')}\\n\"\n",
        "                f\"- Category: {expense.get('category','')}\\n\"\n",
        "                f\"- Total: {expense.get('total','')} {expense.get('currency','')}\\n\"\n",
        "            )\n",
        "        except Exception as e:\n",
        "            reply = f\"Sorry, I ran into an error while parsing the receipt: {e}\"\n",
        "\n",
        "        history.append((\"ðŸ§¾ \" + user_msg, reply))\n",
        "        # clear message + image after handling\n",
        "        return \"\", history, None\n",
        "\n",
        "    # ----- Simple chat / RAG question -----\n",
        "    if message:\n",
        "        answer = answer_question_over_expenses(DEMO_USER_ID, message)\n",
        "        history.append((message, answer))\n",
        "\n",
        "    return \"\", history, None\n",
        "\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ðŸ’³ Personal Expense Assistant (Gemini + SQLite)\")\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=3):\n",
        "            chatbot = gr.Chatbot(height=400)   # ðŸ‘ˆ default tuple format\n",
        "            msg = gr.Textbox(label=\"Message\")\n",
        "            image = gr.Image(label=\"Upload receipt (optional)\", type=\"pil\")\n",
        "            send_btn = gr.Button(\"Send\")\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\n",
        "                \"### How to use\\n\"\n",
        "                \"- Upload a receipt image and click **Send** to store it.\\n\"\n",
        "                \"- Then ask questions like:\\n\"\n",
        "                \"  - *How much have I spent on groceries?*\\n\"\n",
        "                \"  - *What is my total spending this month?*\"\n",
        "            )\n",
        "\n",
        "    send_btn.click(\n",
        "        chat_fn,\n",
        "        inputs=[msg, chatbot, image],\n",
        "        outputs=[msg, chatbot, image],\n",
        "    )\n",
        "\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "KxWWWVsC-55y",
        "outputId": "acb04239-34b5-4904-b5fe-0fea532f863c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3371730870.py:40: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
            "  chatbot = gr.Chatbot(height=400)   # ðŸ‘ˆ default tuple format\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://35f947d19571c1600c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://35f947d19571c1600c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}